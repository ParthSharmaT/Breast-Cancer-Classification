{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Notebook 3: Pre-Processing the data\n",
    "\n",
    "### Introduction\n",
    "\n",
    " [Data preprocessing](http://www.cs.ccsu.edu/~markov/ccsu_courses/datamining-3.html) is a crucial step for any data analysis problem.  It is often a very good idea to prepare your data in such way to best expose the structure of the problem to the machine learning algorithms that you intend to use.This involves a number of activities such as:\n",
    "* Assigning numerical values to categorical data;\n",
    "* Handling missing values; and\n",
    "* Normalizing the features (so that features on small scales do not dominate when fitting a model to the data).\n",
    "\n",
    "\n",
    "\n",
    "In Notebook-2 NB2_Exploratory data analysis, we explored the data, to help gain insight on the distribution of the data as well as how the attributes correlate to each other. we identified some features of interest. In this notebook I use feature selection to reduce high-dimension data, feature extraction and transformation for dimensionality reduction. \n",
    "\n",
    "### Goal:\n",
    "Find the most predictive features of the data and filter it so it will enhance the predictive power of the analytics model. \n",
    "\n",
    "#### Load data and essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Load libraries for data processing\n",
    "import pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,4) \n",
    "#plt.rcParams['axes.titlesize'] = 'large'\n",
    "\n",
    "data = pd.read_csv('data/clean-data.csv', index_col=False)\n",
    "data.drop('Unnamed: 0',axis=1, inplace=True)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encoding\n",
    "Here, we assign the 30 features to a NumPy array X, and transform the class labels from their original string representation (M and B) into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign predictors to a variable of ndarray (matrix) type\n",
    "array = data.values\n",
    "X = array[:,1:31]\n",
    "y = array[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the class labels from their original string representation (M and B) into integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "#Call the transform method of LabelEncorder on two dummy variables\n",
    "#le.transform (['M', 'B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> *After encoding the class labels(diagnosis) in an array y, the malignant tumors are now represented as class 1(i.e prescence of cancer cells) and the benign tumors are represented as class 0 (i.e no cancer cells detection), respectively*, illustrated by calling the transform method of LabelEncorder on two dummy variables.**\n",
    "\n",
    "\n",
    "#### Assesing Model Accuracy: Split data into training and test sets\n",
    "\n",
    "The simplest method to evaluate the performance of a machine learning algorithm is to use different training and testing datasets. Here I will\n",
    "* Split the available data into a training set and a testing set. (70% training, 30% test)\n",
    "* Train the algorithm on the first part,\n",
    "* make predictions on the second part and \n",
    "* evaluate the predictions against the expected results. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (426,), (143, 30), (143,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##Split data set in train 70% and test 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.25, random_state=7)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Summary of the Data Preprocing Approach used here:\n",
    "\n",
    "1. assign features to a NumPy array X, and transform the class labels from their original string representation (M and B) into integers\n",
    "2. Split data into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
